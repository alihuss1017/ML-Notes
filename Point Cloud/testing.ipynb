{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Generation\n",
    "\n",
    "Importing modules to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import pybullet as p\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import numpy as np \n",
    "import pybullet_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import jdc\n",
    "from IPython.display import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simulation environment with an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_simulator():\n",
    "    p.connect(p.GUI)\n",
    "    p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "    p.loadURDF('plane.urdf')\n",
    "    p.loadURDF('r2d2.urdf', [0,0,1], globalScaling = 1)\n",
    "    p.setGravity(0,0,-10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined below will map the GUI sliders' names and values to a dictionary, and then return this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloud:\n",
    "    @classmethod\n",
    "    def read_params(self, params):\n",
    "        self.params = params\n",
    "        vals = dict()\n",
    "        self.vals = vals\n",
    "        for name, param in self.params.items():\n",
    "            self.vals[name] = p.readUserDebugParameter(param)\n",
    "        return self.vals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function develops the sliders for the parameters in the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to PointCloud\n",
    "@classmethod\n",
    "def camera_placement(self, p_scale = 1., max_dist = 10., show_plot = True, verbose = True):\n",
    "    np.set_printoptions(suppress = True, precision = 4)\n",
    "    self.cam = dict()\n",
    "    self.cam['x'] = p.addUserDebugParameter(' x', -p_scale, p_scale, 0)\n",
    "    self.cam['y'] = p.addUserDebugParameter(' y', -p_scale, p_scale, 0)\n",
    "    self.cam['z'] = p.addUserDebugParameter(' z', -p_scale, p_scale, 0)\n",
    "    self.cam['dist'] = p.addUserDebugParameter(' distance', 0, max_dist, max_dist/2)\n",
    "    self.cam['roll'] = p.addUserDebugParameter(' roll', -180, 180, 0)\n",
    "    self.cam['pitch'] = p.addUserDebugParameter(' pitch', -180, 180, -40)\n",
    "    self.cam['yaw'] = p.addUserDebugParameter(' yaw', -180, 180, 0)\n",
    "    self.cam['upAxisIndex'] = p.addUserDebugParameter(' toggle upAxisIndex', 1,0,1)\n",
    "    self.cam['width'] = p.addUserDebugParameter(' width', 100, 1000, 320)\n",
    "    self.cam['height'] = p.addUserDebugParameter(' height', 100, 1000, 240)\n",
    "    self.cam['fov'] = p.addUserDebugParameter(' fov', 1, 180, 50)\n",
    "    self.cam['near'] = p.addUserDebugParameter(' near', 1e-6, 1, .1)\n",
    "    self.cam['far'] = p.addUserDebugParameter(' far', 1, 100, 10)\n",
    "    self.cam['print'] = p.addUserDebugParameter('print', 1, 0, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generaties the bodies of the camera and its target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to PointCloud\n",
    "@classmethod\n",
    "def generate_bodies(self):\n",
    "    self.target_vis_id = p.createVisualShape(p.GEOM_SPHERE, radius = .01, rgbaColor = [1, 0, 0, .7])\n",
    "    self.target_body = p.createMultiBody(0,-1, self.target_vis_id)\n",
    "    self.camera_vis_id = p.createVisualShape(p.GEOM_BOX, halfExtents = [.02, .05, .02], rgbaColor = [1, 0, 0, .7])\n",
    "    self.camera_body = p.createMultiBody(0,-1, self.camera_vis_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates and saves the depth and RGB images, as well as the point cloud. <br> Since we can't directly extract the focal length of the camera used in Pybullet, we can alternatively calculate it using the field of view and width of the image with the following equation: <br><p style=\"text-align: center;\">$focal\\_length = \\frac{0.5 * image\\_width}{\\tan(\\frac{fov}{2})}$</p>\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to PointCloud\n",
    "@classmethod\n",
    "def generate_images(self):\n",
    "    while 1:\n",
    "        self.values = self.read_params(self.cam)\n",
    "        target_pos = np.array([self.values[c] for c in 'xyz'])\n",
    "        upAxisIndex = (int(self.values['upAxisIndex']) % 2 ) + 1\n",
    "        view_mtx = p.computeViewMatrixFromYawPitchRoll(target_pos, self.values['dist'],self.values['yaw'],self.values['pitch'],self.values['roll'],upAxisIndex=2)         \n",
    "        height = int(self.values['height'])\n",
    "        width = int(self.values['width'])\n",
    "        aspect = width/height\n",
    "        proj_mtx = p.computeProjectionMatrixFOV(self.values['fov'],aspect,self.values['near'], self.values['far'])\n",
    "        p.resetBasePositionAndOrientation(self.target_body, target_pos, [0,0,0,1])\n",
    "        view_mtx = np.array(view_mtx).reshape((4,4),order='F')\n",
    "            \n",
    "        cam_pos = np.dot(view_mtx[:3,:3].T, -view_mtx[:3,3])\n",
    "        cam_euler = np.radians([self.values['pitch'],self.values['roll'],self.values['yaw']])\n",
    "        cam_quat = p.getQuaternionFromEuler(cam_euler)\n",
    "        p.resetBasePositionAndOrientation(self.camera_body, cam_pos, cam_quat)\n",
    "\n",
    "        view_mtx = view_mtx.reshape(-1, order='F')\n",
    "        self.img = p.getCameraImage(width, height, view_mtx, proj_mtx, renderer = p.ER_TINY_RENDERER)\n",
    "        width, height, self.rgb, self.depth, mask = self.img\n",
    "        self.depth *= 255\n",
    "        self.depth = np.where(self.depth < 255, self.depth*.5, self.depth)\n",
    "        cv2.imwrite('rgb.png',cv2.cvtColor(self.rgb,cv2.COLOR_RGBA2BGR))\n",
    "        cv2.imwrite('depth.png', self.depth)\n",
    "        self.rgb = cv2.imread(\"rgb.png\")\n",
    "        self.rgb = cv2.cvtColor(self.rgb, cv2.COLOR_BGRA2RGB)\n",
    "        cx = self.depth.shape[1] // 2\n",
    "        cy = self.depth.shape[0] // 2\n",
    "\n",
    "        xx, yy = np.meshgrid(np.arange(self.depth.shape[1]), np.arange(self.depth.shape[0]))\n",
    "        f = .5 * self.depth.shape[1] / math.tan(self.values['fov']*(math.pi/180)/2)\n",
    "        fx = fy = f\n",
    "        xx = (xx - cx) / fx * self.depth\n",
    "        yy = (yy - cy) / fy * self.depth\n",
    "\n",
    "        points = np.column_stack((xx.flatten(), yy.flatten(), self.depth.flatten()))\n",
    "\n",
    "            # Assign a color to each point in the point cloud\n",
    "        colors = self.rgb.reshape(-1, 3) / 255.0\n",
    "\n",
    "            # Create the point cloud and save it to a PLY file\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        o3d.io.write_point_cloud(\"testingpointcloud.ply\", pcd)\n",
    "        old_print_val = 1\n",
    "        if old_print_val != self.values['print']:\n",
    "            old_print_val = self.values['print']\n",
    "            print(\"\\n========================================\")\n",
    "            print(f\"VIEW MATRIX : \\n{np.array_str(view_mtx)}\")\n",
    "            print(f\"PROJECTION MATRIX : \\n{np.array(proj_mtx)}\")\n",
    "            if True:\n",
    "                print(f\"target position : {np.array_str(target_pos)}\")\n",
    "                print(f\"distance : {self.values['dist']:.2f}\")\n",
    "                print(f\"yaw : {self.values['yaw']:.2f}\")\n",
    "                print(f\"pitch : {self.values['pitch']:.2f}\")\n",
    "                print(f\"roll : {self.values['roll']:.2f}\")\n",
    "                print(f\"width : {width:d}\")\n",
    "                print(f\"height : {height:d}\")\n",
    "                print(f\"fov : {self.values['fov']:.1f}\")\n",
    "                print(f\"aspect : {aspect:.2f}\")\n",
    "                print(f\"nearVal : {self.values['near']:.2f}\")\n",
    "                print(f\"farVal : {self.values['far']:.2f}\")\n",
    "            print(\"========================================\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB and Depth Images\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src='rgb.png'></td>\n",
    "    <td><img src='depth.png'></td>\n",
    "    <td><img src='pointcloud.png'></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "Not connected to physics server.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m PointCloud\u001b[39m.\u001b[39mcamera_placement()\n\u001b[0;32m      3\u001b[0m PointCloud\u001b[39m.\u001b[39mgenerate_bodies()\n\u001b[1;32m----> 4\u001b[0m PointCloud\u001b[39m.\u001b[39;49mgenerate_images()\n",
      "File \u001b[1;32m<string>:5\u001b[0m, in \u001b[0;36mgenerate_images\u001b[1;34m(self)\u001b[0m\n",
      "Cell \u001b[1;32mIn [3], line 8\u001b[0m, in \u001b[0;36mPointCloud.read_params\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvals \u001b[39m=\u001b[39m vals\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mitems():\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvals[name] \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mreadUserDebugParameter(param)\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvals\n",
      "\u001b[1;31merror\u001b[0m: Not connected to physics server."
     ]
    }
   ],
   "source": [
    "initialize_simulator()\n",
    "PointCloud.camera_placement()\n",
    "PointCloud.generate_bodies()\n",
    "PointCloud.generate_images()\n",
    "\n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "618e6f0a0f5e6103729bcee527c32647b6f1ff8ebde56d9153a8fa5e32a14150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
