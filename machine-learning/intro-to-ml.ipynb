{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ML\n",
    "## Part 1: Reading Data\n",
    "\n",
    "The read_csv() function reads data and describe() gives a summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"C:/Users/ali49/Downloads/winequality-red.csv\")\n",
    "print(dataset.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Your First Machine Learning Model\n",
    "\n",
    "We can output all of our features by using the columns() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Prediction Target\n",
    "\n",
    "You can pull out a variable with dot notation, and this single column is stored in a series. The prediction target is the column we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.quality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Features\n",
    "Select features by using a column list. We'll use describe() and head() to look at this section of the data. head() looks at the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fixed acidity', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "X = dataset[features]\n",
    "print(X.describe())\n",
    "print(X.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Your Model\n",
    "We'll be using a decision tree to predict our models. To learn about decision trees: https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052<br></br>\n",
    "These are the steps to building a model:\n",
    "1. Define: What type of model?\n",
    "2. Fit: Capture patterns from provided data.\n",
    "3. Predict: Self-explanatory.\n",
    "4. Evaluate: Determine accuracy of predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state = 1)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "In practice, you'll want to make predictions for new players instead of players we already have in the training data. But for this example, we'll be making predictions for the first few rows of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions for the following 5 players\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(model.predict(X.head()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Model Validation\n",
    "\n",
    "A common evaluation metric used in practice is mean absolute error. The mean absolute error to is equal to the average of the sum of the difference of the actual and predicted values for every training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = model.predict(X)\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem with \"In-Sample\" Scores\n",
    "If the pattern in training data doesn't hold in new data, the model will be very inaccurate in practice. We will use the train_test_split function to seperate our testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X,y, random_state = 1)\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(train_X, train_y)\n",
    "val_predictions = model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Underfitting and Overfitting\n",
    "\n",
    "Overfitting is when the the model matches the training data almost perfectly, but does poorly when given new data. This is because when there are many leaves in a decision tree, there will be very little examples under each leave. <br></br>\n",
    "Underfitting is when the model performs poorly even in training data due to a lack of features. \n",
    "\n",
    "<br>\n",
    "We can use the max_leaf_nodes argument to control this overfitting vs underfitting issue by comparing different numbers of max_leaf_nodes with MAE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_nodes, random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, predictions)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_leaf_nodes in [5,50,500,5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(f'Max leaf nodes: {max_leaf_nodes} \\t \\t Mean Absolute Error: {my_mae}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above it is evident that using a max_leaf_nodes value of 500 will suffice for optimizing the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "618e6f0a0f5e6103729bcee527c32647b6f1ff8ebde56d9153a8fa5e32a14150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
